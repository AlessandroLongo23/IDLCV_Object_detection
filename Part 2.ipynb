{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import json\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torchvision import transforms\n",
    "from collections import Counter\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 256"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Custom Dataset class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProposalDataset(Dataset):\n",
    "    def __init__(self, labeled_proposals_dir, images_dir, image_ids, label_encoder, transform=None):\n",
    "        self.labeled_proposals_dir = labeled_proposals_dir\n",
    "        self.images_dir = images_dir\n",
    "        self.image_ids = image_ids\n",
    "        self.transform = transform\n",
    "        self.label_encoder = label_encoder\n",
    "\n",
    "        self.samples = []\n",
    "        for image_id in self.image_ids:\n",
    "            # Strip file extension if present\n",
    "            image_id = os.path.splitext(image_id)[0]\n",
    "            proposal_file = os.path.join(self.labeled_proposals_dir, image_id + '_labeled_proposals.npy')\n",
    "\n",
    "            # Search for image files with known extensions (case-insensitive)\n",
    "            image_files = []\n",
    "            pattern = os.path.join(self.images_dir, image_id + '.jpg')\n",
    "            image_files.extend(glob.glob(pattern))\n",
    "\n",
    "            image_path = image_files[0]\n",
    "\n",
    "            labeled_proposals = np.load(proposal_file, allow_pickle=True)\n",
    "            for proposal in labeled_proposals:\n",
    "                if 'box' not in proposal or 'label' not in proposal:\n",
    "                    print(f\"Invalid proposal format in '{proposal_file}'. Skipping proposal.\")\n",
    "                    continue\n",
    "                box = proposal['box']\n",
    "                label = proposal['label']\n",
    "                self.samples.append({'image_path': image_path, 'box': box, 'label': label})\n",
    "\n",
    "        print(f\"Loaded {len(self.samples)} samples for dataset with {len(self.image_ids)} image IDs.\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.samples[idx]\n",
    "        image_path = sample['image_path']\n",
    "        box = sample['box']\n",
    "        label = sample['label']\n",
    "\n",
    "        # Load image\n",
    "        with Image.open(image_path) as img:\n",
    "            # Crop the proposal\n",
    "            x, y, w, h = box\n",
    "            cropped_img = img.crop((x, y, x + w, y + h)).convert('RGB')\n",
    "            if self.transform:\n",
    "                cropped_img = self.transform(cropped_img)\n",
    "            else:\n",
    "                # Default transformations\n",
    "                cropped_img = cropped_img.resize((IMG_SIZE, IMG_SIZE))\n",
    "                cropped_img = np.array(cropped_img).astype(np.float32) / 255.0\n",
    "                # Convert HWC to CHW format\n",
    "                cropped_img = np.transpose(cropped_img, (2, 0, 1))\n",
    "                cropped_img = torch.tensor(cropped_img)\n",
    "\n",
    "        # Encode label\n",
    "        label_encoded = self.label_encoder.transform([label])[0]\n",
    "        label_encoded = torch.tensor(label_encoded, dtype=torch.long)\n",
    "\n",
    "        return cropped_img, label_encoded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handle class Imbalance\n",
    "\n",
    "\n",
    "1. The CrossEntropy fiunction can accept a weight parameter, which assigns a weight to each class. This makes the loss fucntion pay more attention to underrrepresented classes.\n",
    "2. To compute_class_weights: weights= total_samples/(num_classes*count)\n",
    "3. The WeightedRandomSampler allows the DataLoader to sample elements based on assigned weights, ensuring that each class is represented proportionally during training.\n",
    "\n",
    "Basically Instead of using a fixed ratio of 75-25 it calculates the ratios by counting the negative and positive classes. Then this is "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_class_weights(dataset, num_classes):\n",
    "    \"\"\"\n",
    "    Computes class weights based on the dataset.\n",
    "\n",
    "    Args:\n",
    "        dataset (Dataset): Instance of ProposalDataset.\n",
    "        num_classes (int): Total number of classes.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: Class weights.\n",
    "    \"\"\"\n",
    "    # Count the frequency of each class\n",
    "    labels = [sample['label'] for sample in dataset.samples]\n",
    "    label_counts = Counter(labels)\n",
    "    total_samples = len(labels)\n",
    "    class_weights = []\n",
    "\n",
    "    for label in dataset.label_encoder.classes_:\n",
    "        count = label_counts.get(label, 0)\n",
    "        weight = total_samples / (num_classes * count) if count > 0 else 0\n",
    "        class_weights.append(weight)\n",
    "\n",
    "    class_weights = torch.tensor(class_weights, dtype=torch.float)\n",
    "    return class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sampler(dataset, class_weights):\n",
    "    \"\"\"\n",
    "    Creates a weighted sampler to handle class imbalance.\n",
    "\n",
    "    Args:\n",
    "        dataset (Dataset): Instance of ProposalDataset.\n",
    "        class_weights (torch.Tensor): Class weights.\n",
    "\n",
    "    Returns:\n",
    "        WeightedRandomSampler: Sampler for DataLoader.\n",
    "    \"\"\"\n",
    "    # Get the labels for all samples\n",
    "    labels = [dataset.label_encoder.transform([sample['label']])[0] for sample in dataset.samples]\n",
    "    sample_weights = [class_weights[label] for label in labels]\n",
    "    sampler = WeightedRandomSampler(sample_weights, num_samples=len(sample_weights), replacement=True)\n",
    "    return sampler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DataLoader function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_loaders(labeled_proposals_dir, images_dir, splits_file, batch_size=32):\n",
    "    # Load splits\n",
    "    with open(splits_file, 'r') as f:\n",
    "        splits = json.load(f)\n",
    "    train_ids = splits.get('train', [])\n",
    "    test_ids = splits.get('test', [])\n",
    "\n",
    "    # Strip file extensions from image IDs\n",
    "    train_ids = [os.path.splitext(image_id)[0] for image_id in train_ids]\n",
    "    test_ids = [os.path.splitext(image_id)[0] for image_id in test_ids]\n",
    "\n",
    "    # Further split training IDs for validation\n",
    "    train_ids, val_ids = train_test_split(train_ids, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Fit label encoder on all labels\n",
    "    label_encoder = LabelEncoder()\n",
    "    all_labels = []\n",
    "    for ids in [train_ids, val_ids, test_ids]:\n",
    "        for image_id in ids:\n",
    "            image_id = os.path.splitext(image_id)[0]  # Ensure no extension\n",
    "            proposal_file = os.path.join(labeled_proposals_dir, image_id + '_labeled_proposals.npy')\n",
    "            if os.path.exists(proposal_file):\n",
    "                labeled_proposals = np.load(proposal_file, allow_pickle=True)\n",
    "                labels = [proposal['label'] for proposal in labeled_proposals]\n",
    "                all_labels.extend(labels)\n",
    "    label_encoder.fit(all_labels)\n",
    "    num_classes = len(label_encoder.classes_)\n",
    "\n",
    "    # Define transformations\n",
    "    \"\"\"  transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),  # Converts to [0, 1] and rearranges dimensions\n",
    "    ])\n",
    "    \"\"\"\n",
    "    \"\"\"    transform = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "    ]) \"\"\"\n",
    "    transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.Pad((0, 0, 256, 256), fill=0, padding_mode='constant'),  # Adjust padding as needed\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "    # Create datasets\n",
    "    train_dataset = ProposalDataset(labeled_proposals_dir, images_dir, train_ids, label_encoder, transform=transform)\n",
    "    val_dataset = ProposalDataset(labeled_proposals_dir, images_dir, val_ids, label_encoder, transform=transform)\n",
    "    test_dataset = ProposalDataset(labeled_proposals_dir, images_dir, test_ids, label_encoder, transform=transform)\n",
    "\n",
    "    # Compute class weights\n",
    "    class_weights = compute_class_weights(train_dataset, num_classes)\n",
    "\n",
    "    # Create sampler for training dataset\n",
    "    sampler = create_sampler(train_dataset, class_weights)\n",
    "\n",
    "    # Create DataLoaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, sampler=sampler)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    # Print number of samples\n",
    "    print(f\"Number of training samples: {len(train_dataset)}\")\n",
    "    print(f\"Number of validation samples: {len(val_dataset)}\")\n",
    "    print(f\"Number of testing samples: {len(test_dataset)}\")\n",
    "\n",
    "    return train_loader, val_loader, test_loader, num_classes, label_encoder, class_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProposalClassifierCNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(ProposalClassifierCNN, self).__init__()\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2)\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2)\n",
    "        )\n",
    "    \n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Linear(64 * (IMG_SIZE / 4.0) * (IMG_SIZE / 4.0), 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5)\n",
    "        )\n",
    "        \n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        \n",
    "        x = x.view(x.size(0), -1)\n",
    "        \n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation Funtion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, data_loader, criterion, device):\n",
    "    \"\"\"\n",
    "    Evaluates the model on a dataset.\n",
    "\n",
    "    Args:\n",
    "        model (nn.Module): Trained model.\n",
    "        data_loader (DataLoader): DataLoader for the dataset.\n",
    "        criterion: Loss function.\n",
    "        device: Device ('cpu' or 'cuda').\n",
    "\n",
    "    Returns:\n",
    "        float: Average loss.\n",
    "        float: Accuracy.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in data_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            running_loss += loss.item() * images.size(0)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total_correct += (predicted == labels).sum().item()\n",
    "            total_samples += labels.size(0)\n",
    "\n",
    "    avg_loss = running_loss / total_samples\n",
    "    accuracy = total_correct / total_samples\n",
    "\n",
    "    return avg_loss, accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, num_epochs, criterion, optimizer, device):\n",
    "    model.to(device)\n",
    "    history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': []}\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        total_correct = 0\n",
    "        total_samples = 0\n",
    "\n",
    "        with tqdm(total=len(train_loader), desc=f'Epoch {epoch+1}/{num_epochs}', unit='batch') as pbar:\n",
    "            for images, labels in train_loader:\n",
    "                images = images.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                running_loss += loss.item() * images.size(0)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total_correct += (predicted == labels).sum().item()\n",
    "                total_samples += labels.size(0)\n",
    "\n",
    "                # Update progress bar\n",
    "                pbar.set_postfix({'Loss': loss.item()})\n",
    "                pbar.update(1)\n",
    "\n",
    "        epoch_loss = running_loss / total_samples\n",
    "        epoch_acc = total_correct / total_samples\n",
    "        history['train_loss'].append(epoch_loss)\n",
    "        history['train_acc'].append(epoch_acc)\n",
    "\n",
    "        # Validation\n",
    "        val_loss, val_acc = evaluate_model(model, val_loader, criterion, device)\n",
    "        history['val_loss'].append(val_loss)\n",
    "        history['val_acc'].append(val_acc)\n",
    "\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], '\n",
    "              f'Train Loss: {epoch_loss:.4f}, Train Acc: {epoch_acc:.4f}, '\n",
    "              f'Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\\n')\n",
    "\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def plot_training_history(history):\n",
    "    epochs = range(1, len(history['train_loss']) + 1)\n",
    "\n",
    "    # Plot Loss\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs, history['train_loss'], 'b-', label='Training Loss')\n",
    "    plt.plot(epochs, history['val_loss'], 'r-', label='Validation Loss')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    # Plot Accuracy\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs, history['train_acc'], 'b-', label='Training Accuracy')\n",
    "    plt.plot(epochs, history['val_acc'], 'r-', label='Validation Accuracy')\n",
    "    plt.title('Training and Validation Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "def plot_confusion_matrix(model, data_loader, label_encoder, device):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for images, labels in data_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=label_encoder.classes_)\n",
    "    disp.plot(cmap=plt.cm.Blues)\n",
    "    plt.title('Confusion Matrix on Validation Set')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_proposals_dir = './Potholes/NMS/Labeled_Proposals_SS'\n",
    "images_dir = './Potholes/annotated-images/train'\n",
    "splits_file = './Potholes/splits.json'                 # Update this path\n",
    "\n",
    "# Hyperparameters\n",
    "num_epochs = 10\n",
    "batch_size = 64\n",
    "learning_rate = 1e-3\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Get DataLoaders\n",
    "train_loader, val_loader, test_loader, num_classes, label_encoder, class_weights = get_data_loaders(\n",
    "    labeled_proposals_dir, images_dir, splits_file, batch_size=batch_size\n",
    ")\n",
    "\n",
    "# Initialize model\n",
    "model = ProposalClassifierCNN(num_classes)\n",
    "\n",
    "# Loss and optimizer\n",
    "# Use class weights in the loss function to handle class imbalance\n",
    "class_weights_tensor = class_weights.to(device)\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights_tensor)\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Train the model\n",
    "# Correctly unpack the returned tuple\n",
    "model, history = train_model(model, train_loader, val_loader, num_epochs, criterion, optimizer, device)\n",
    "\n",
    "# Now you can use both `model` and `history` as needed\n",
    "# For example, evaluate on the test set\n",
    "test_loss, test_acc = evaluate_model(model, test_loader, criterion, device)\n",
    "print(f'Test Loss: {test_loss:.4f}, Test Accuracy: {test_acc:.4f}')\n",
    "\n",
    "# Save the model\n",
    "torch.save(model.state_dict(), 'proposal_classifier.pth')\n",
    "print(\"Model saved as 'proposal_classifier.pth'.\")\n",
    "\n",
    "# Optionally, plot training history and confusion matrix here\n",
    "plot_training_history(history)\n",
    "plot_confusion_matrix(model, val_loader, label_encoder, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fine tune pretrained networks(on ImageNet) by freezing all leyers but the final fully connected layer to match the number of classes in your dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torchvision.models as models\n",
    "class ProposalClassifierResNet(nn.Module):\n",
    "    def __init__(self, num_classes, pretrained=True):\n",
    "        super(ProposalClassifierResNet, self).__init__()\n",
    "        # Load pre-trained ResNet-18\n",
    "        self.model = models.resnet18(pretrained=pretrained)\n",
    "        \n",
    "        # Freeze all layers if you don't want to fine-tune\n",
    "        for param in self.model.parameters():\n",
    "            param.requires_grad = False\n",
    "        \n",
    "        # Replace the final fully connected layer\n",
    "        num_ftrs = self.model.fc.in_features\n",
    "        self.model.fc = nn.Linear(num_ftrs, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directories (update paths accordingly)\n",
    "labeled_proposals_dir = './Potholes/NMS/Labeled_Proposals_SS'\n",
    "images_dir = './Potholes/annotated-images/train'\n",
    "splits_file = './Potholes/splits.json'\n",
    "\n",
    "# Hyperparameters\n",
    "num_epochs = 2\n",
    "batch_size = 32\n",
    "learning_rate = 0.001\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Get DataLoaders\n",
    "train_loader, val_loader, test_loader, num_classes, label_encoder, class_weights = get_data_loaders(\n",
    "    labeled_proposals_dir, images_dir, splits_file, batch_size=batch_size\n",
    ")\n",
    "\n",
    "# Initialize pre-trained ResNet model\n",
    "model = ProposalClassifierResNet(num_classes, pretrained=True)\n",
    "model = model.to(device)\n",
    "\n",
    "# Optionally, fine-tune some layers\n",
    "# Example: Unfreeze layer4\n",
    "for name, param in model.model.named_parameters():\n",
    "    if \"layer4\" in name:\n",
    "        param.requires_grad = True\n",
    "\n",
    "# Define loss and optimizer\n",
    "class_weights_tensor = class_weights.to(device)\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights_tensor)\n",
    "\n",
    "# Only parameters that require gradients are passed to the optimizer\n",
    "optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=learning_rate)\n",
    "\n",
    "# Train the model\n",
    "model, history = train_model(model, train_loader, val_loader, num_epochs, criterion, optimizer, device)\n",
    "\n",
    "# Evaluate on test set\n",
    "test_loss, test_acc = evaluate_model(model, test_loader, criterion, device)\n",
    "print(f'Test Loss: {test_loss:.4f}, Test Accuracy: {test_acc:.4f}')\n",
    "\n",
    "# Save the model\n",
    "torch.save(model.state_dict(), 'proposal_classifier_resnet.pth')\n",
    "print(\"Model saved as 'proposal_classifier_resnet.pth'.\")\n",
    "\n",
    "# Plot training history and confusion matrix\n",
    "plot_training_history(history)\n",
    "plot_confusion_matrix(model, val_loader, label_encoder, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProposalClassifierVGG16(nn.Module):\n",
    "    def __init__(self, num_classes, pretrained=True, freeze_features=True):\n",
    "        super(ProposalClassifierVGG16, self).__init__()\n",
    "        # Load pre-trained VGG16 model\n",
    "        self.model = models.vgg16(pretrained=pretrained)\n",
    "        \n",
    "        if freeze_features:\n",
    "            # Freeze feature extraction layers\n",
    "            for param in self.model.features.parameters():\n",
    "                param.requires_grad = False\n",
    "        \n",
    "        # Modify the classifier to match num_classes\n",
    "        # Original classifier: [4096, 4096, 1000]\n",
    "        self.model.classifier[6] = nn.Linear(self.model.classifier[6].in_features, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directories (update paths accordingly)\n",
    "labeled_proposals_dir = './Potholes/NMS/Labeled_Proposals_SS'\n",
    "images_dir = './Potholes/annotated-images/train'\n",
    "splits_file = './Potholes/splits.json'\n",
    "\n",
    "# Hyperparameters\n",
    "num_epochs = 2\n",
    "batch_size = 32\n",
    "learning_rate = 0.001\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')\n",
    "\n",
    "# Get DataLoaders\n",
    "train_loader, val_loader, test_loader, num_classes, label_encoder = get_data_loaders(\n",
    "    labeled_proposals_dir, images_dir, splits_file, batch_size=batch_size, background_label='background', background_ratio=0.75\n",
    ")\n",
    "\n",
    "# Initialize pre-trained VGG16 model\n",
    "model = ProposalClassifierVGG16(num_classes=num_classes, pretrained=True, freeze_features=True)\n",
    "model = model.to(device)\n",
    "\n",
    "# Define loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Only parameters that require gradients are passed to the optimizer\n",
    "optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=learning_rate)\n",
    "\n",
    "# Train the model\n",
    "model, history = train_model(model, train_loader, val_loader, num_epochs, criterion, optimizer, device)\n",
    "\n",
    "# Evaluate on test set\n",
    "test_loss, test_acc = evaluate_model(model, test_loader, criterion, device)\n",
    "print(f'Test Loss: {test_loss:.4f}, Test Accuracy: {test_acc:.4f}')\n",
    "\n",
    "# Save the model\n",
    "torch.save(model.state_dict(), 'proposal_classifier_vgg16.pth')\n",
    "print(\"Model saved as 'proposal_classifier_vgg16.pth'.\")\n",
    "\n",
    "# Plot training history and confusion matrix\n",
    "plot_training_history(history)\n",
    "plot_confusion_matrix(model, val_loader, label_encoder, device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

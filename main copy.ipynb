{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Introduction\n",
    "\n",
    "## 1.1. Goal\n",
    "The goal of the project is to build a deep-learning model that is able to detect potholes.\n",
    "\n",
    "## 1.2. Dataset\n",
    "The pothole dataset contains 665 images annotated with bounding boxes around potholes.The annotations are in XML format(similar to Pascal VOC). There is a splits.json file in which training-test sets are defined."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- - -\n",
    "- - -\n",
    "# 2. Object proposals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. Visualize the dataset\n",
    "> Familiarise yourself with the data and visualize some examples with the ground-truth bounding boxes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.globalConst import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Potholes.DatasetAnalyzer import DatasetAnalyzer\n",
    "\n",
    "dataset_analyzer = DatasetAnalyzer()\n",
    "dataset_analyzer.visualize_samples('train', num_samples=6, rows=2, cols=3)\n",
    "print(dataset_analyzer.visualize_image_with_annotations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Count total images\n",
    "train_images = len(os.listdir(TRAIN_DIR))\n",
    "val_images = len(os.listdir(VAL_DIR))\n",
    "test_images = len(os.listdir(TEST_DIR))\n",
    "total_images = train_images + val_images + test_images\n",
    "\n",
    "print(\n",
    "    f'The dataset contains {total_images} images, with the following distribution:',\n",
    "    f'- Training: {train_images} ({train_images / total_images * 100:.0f}%)',\n",
    "    f'- Validation: {val_images} ({val_images / total_images * 100:.0f}%)',\n",
    "    f'- Testing: {test_images} ({test_images / total_images * 100:.0f}%)',\n",
    "    sep='\\n'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get unique image sizes and aspect ratios\n",
    "unique_sizes, unique_aspect_ratios = dataset_analyzer.get_unique_image_sizes_and_ratios()\n",
    "print(f\"Number of unique image sizes: {len(unique_sizes)}\")\n",
    "print(f\"Number of unique image aspect ratios: {len(unique_aspect_ratios)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count total annotations and track objects per image\n",
    "total_annotations, objects_per_image = dataset_analyzer.count_annotations()\n",
    "print(f\"Total number of pothole annotations: {total_annotations}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_objects, image_indexes = dataset_analyzer.find_images_with_max_objects(objects_per_image)\n",
    "min_objects = min(objects_per_image.values())\n",
    "print(f\"Maximum number of objects in an image: {max_objects}\")\n",
    "print(f\"Minimum number of objects in an image: {min_objects}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Image(s) with the maximum number of potholes ({max_objects}):\")\n",
    "for idx in image_indexes: \n",
    "    dataset_analyzer.visualize_image_with_annotations('train', idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- - -\n",
    "## 2.2. Calculate object proposals\n",
    "> Extract object proposals for all the images of the dataset (e.g. Selecting Search, Edge Boxes, etc). \n",
    "> \n",
    "> ``` admonition\n",
    "> Note that you may have to resize the images before you run SS for better efficiency. \n",
    "> ```\n",
    "\n",
    "The goal is to generate candidate regions in each image that may contain potholes using object proposal algorithms.\n",
    "\n",
    "**What are object proposals?**\n",
    "Regions in an image that are likely to contain objects of interest. They allow to reduce the search space for the object detection models by focusing on promising areas.\n",
    "\n",
    "Some moethods:\n",
    "\n",
    "**Selective Search(SS):**\n",
    "- It groups pixels based on color, texture, size and shape compatibility. Hierarchical grouping leads to region proposals.\n",
    "\n",
    "**Edge Boxes:**\n",
    "- Score boxes based on the number of enclosed eedges. It is faster than SS and generates high-quality proposals\n",
    "\n",
    "How to extract the proposals?\n",
    "\n",
    "1. Resize the images to spped up the process(specially with SS it is neccessary)\n",
    "2. Implementation of the algorithm\n",
    "3. Iterate over the dataset and aply the algo\n",
    "4. Save the proposals as numpy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from RegionProposals.ProposalExtractor import ProposalExtractor\n",
    "proposal_extractor = ProposalExtractor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract the proposals with both algorithms (unnecessary if the proposals are already extracted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# proposal_extractor.extract_with('selective_search')\n",
    "# proposal_extractor.extract_with('edge_boxes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also plot an example of the generated proposals for an image in the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proposal_extractor.visualize_top_proposals(idx=EXAMPLE_IDX, alg=\"selective_search\", top_n=10)\n",
    "proposal_extractor.visualize_top_proposals(idx=EXAMPLE_IDX, alg=\"edge_boxes\", top_n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- - -\n",
    "## 2.3. Proposals evaluation\n",
    "> Evaluate the extracted proposals on the training set of the dataset and determine the number of required proposals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two metrics produce valuable insights about the algorithms perofrmance in generating areas of interests.\n",
    "- **Pascal-Recall:** The percentage of ground-truth objects that have at least one proposal overlapping with them at an IoU (Intersection over Union) greater than or equal to a threshold (typically 0.5). It measures how well the proposals cover the actual objects in the dataset.\n",
    "- **MABO(Mean Average Best Overlap)::**  For each ground-truth object, find the proposal with the highest IoU. MABO is the average of these maximum IoUs over all ground-truth objects. It assesses the localization quality of the proposals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from RegionProposals.ProposalEvaluator import ProposalEvaluator\n",
    "proposal_evaluator = ProposalEvaluator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the number of proposals to evaluate\n",
    "num_proposals_list = [1, 8, 64, 512, 2048]  \n",
    "iou_threshold = 0.7\n",
    "\n",
    "# Evaluate Selective Search\n",
    "results_ss = proposal_evaluator.evaluate_proposals(\n",
    "    alg='selective_search',\n",
    "    num_proposals_list=num_proposals_list,\n",
    "    iou_threshold=iou_threshold\n",
    ")\n",
    "\n",
    "# Evaluate Edge Boxes\n",
    "results_eb = proposal_evaluator.evaluate_proposals(\n",
    "    alg='edge_boxes',\n",
    "    num_proposals_list=num_proposals_list,\n",
    "    iou_threshold=iou_threshold\n",
    ")\n",
    "\n",
    "# Plot Pascal-Recall vs. Number of Proposals\n",
    "proposal_evaluator.plot_metric_vs_proposals(\n",
    "    num_proposals_list=num_proposals_list,\n",
    "    metric_ss=results_ss['recalls'],\n",
    "    metric_eb=results_eb['recalls'],\n",
    "    metric_name='Pascal-Recall'\n",
    ")\n",
    "\n",
    "# Plot MABO vs. Number of Proposals\n",
    "proposal_evaluator.plot_metric_vs_proposals(\n",
    "    num_proposals_list=num_proposals_list,\n",
    "    metric_ss=results_ss['mabo'],\n",
    "    metric_eb=results_eb['mabo'],\n",
    "    metric_name='MABO'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proposal_evaluator.display_ground_truth_and_proposals(idx=EXAMPLE_IDX, alg='selective_search', top_n=10)\n",
    "proposal_evaluator.display_ground_truth_and_proposals(idx=EXAMPLE_IDX, alg='edge_boxes', top_n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- - -\n",
    "- - -\n",
    "# 3. Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1. Proposal labeling\n",
    "> Prepare the proposals for the training of the object detector. This requires assigning a label (i.e., class or background label) to each proposal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyzes the IoU Threshold and marks as true the\n",
    "\n",
    "A possible concern could have been that if letÂ´s say three propsal with a high IoU with the ground trough higher than 0.5 are all labelled positive, we would have multiple propsals for each object. This could be a problem in a multiple class setup, where excesive positive proposals for the same object could result in class imbalance. Additionally a high number of overlapping proposals could introduce redundancy,making training less efficient.\n",
    "\n",
    "On the other hand having multiple proposals covering covering the same object from different angles and positions can provide different training examples. It could serve as a sort of Data-Augmentation. It can also ensure that there is enough training samples for less frequent objects: such as for example a very small pothole.\n",
    "\n",
    "Here we call the evaluator method for the assignment (unnecessary if already assigned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# proposal_evaluator.assign_labels_to_proposals(k_1=0.3, k_2=0.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then we plot the result for an example image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proposal_evaluator.visualize_labeled_proposals(idx=EXAMPLE_IDX, alg='selective_search')\n",
    "proposal_evaluator.visualize_labeled_proposals(idx=EXAMPLE_IDX, alg='edge_boxes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- - -\n",
    "## 3.2. Custom Data loader\n",
    "> Build a dataloader for the object detection task. \n",
    "> \n",
    "> ```admonition\n",
    "> Think about the class imbalance issue of the background proposals\n",
    "> ```\n",
    "\n",
    "For the data loader we need to define the batch size and the ratio between the number of potholes and background, to avoid the class imbalance issue.\n",
    "Then, after defining the data transformations, we can build the data loader such that it takes the bounding box proposals as input and their generated label as target.\n",
    "\n",
    "*See ProposalDataset class in ProposalDataset.py*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- - -\n",
    "## 3.3. Handle class imbalance\n",
    "\n",
    "1. The CrossEntropy fiunction can accept a weight parameter, which assigns a weight to each class. This makes the loss fucntion pay more attention to underrrepresented classes.\n",
    "2. To compute_class_weights: weights= total_samples/(num_classes*count)\n",
    "3. The WeightedRandomSampler allows the DataLoader to sample elements based on assigned weights, ensuring that each class is represented proportionally during training.\n",
    "\n",
    "Basically Instead of using a fixed ratio of 75-25 it calculates the ratios by counting the negative and positive classes. Then this is "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import torch\n",
    "\n",
    "def compute_class_weights(dataset, num_classes):\n",
    "    labels = [sample['label'] for sample in dataset.samples]\n",
    "    label_counts = Counter(labels)\n",
    "    total_samples = len(labels)\n",
    "    class_weights = []\n",
    "\n",
    "    for label in dataset.label_encoder.classes_:\n",
    "        count = label_counts.get(label, 0)\n",
    "        weight = total_samples / (num_classes * count) if count > 0 else 0\n",
    "        class_weights.append(weight)\n",
    "\n",
    "    class_weights = torch.tensor(class_weights, dtype=torch.float)\n",
    "    return class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, WeightedRandomSampler\n",
    "\n",
    "def create_sampler(dataset, class_weights):\n",
    "    labels = [dataset.label_encoder.transform([sample['label']])[0] for sample in dataset.samples]\n",
    "    sample_weights = [class_weights[label] for label in labels]\n",
    "    sampler = WeightedRandomSampler(sample_weights, num_samples=len(sample_weights), replacement=True)\n",
    "    return sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from torchvision import transforms\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from RegionProposals.ProposalDataset import ProposalDataset\n",
    "\n",
    "splits = json.load(open(f'./Potholes/splits.json', 'r'))\n",
    "    \n",
    "train_ids = splits.get('train', [])\n",
    "val_ids = splits.get('val', [])\n",
    "test_ids = splits.get('test', [])\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "all_labels = []\n",
    "for indices, split in [(train_ids, 'train'), (val_ids, 'val'), (test_ids, 'test')]:\n",
    "    for idx in indices:\n",
    "        labeled_proposals = json.load(open(f'{ROOT_DIR}/{split}/img-{idx}/selective_search.json')) \n",
    "        labels = [proposal['label'] for proposal in labeled_proposals]\n",
    "        all_labels.extend(labels)\n",
    "            \n",
    "label_encoder.fit(all_labels)\n",
    "num_classes = len(label_encoder.classes_)\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "train_dataset = ProposalDataset('train', label_encoder, transform=transform)\n",
    "val_dataset = ProposalDataset('val', label_encoder, transform=transform)\n",
    "test_dataset = ProposalDataset('test', label_encoder, transform=transform)\n",
    "\n",
    "class_weights = compute_class_weights(train_dataset, num_classes)\n",
    "sampler = create_sampler(train_dataset, class_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- - -\n",
    "- - -\n",
    "# 4. Models and training\n",
    "\n",
    "> Build a convolutional neural network to classify object proposals ($N+1$ classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1. Custom CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from Models.CNN import CNN\n",
    "\n",
    "num_epochs = 10\n",
    "batch_size = 64\n",
    "learning_rate = 1e-3\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, sampler=sampler)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "model = CNN(device, num_classes)\n",
    "\n",
    "class_weights_tensor = class_weights.to(device)\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights_tensor)\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "model.train_(train_loader, val_loader, num_epochs, criterion, optimizer)\n",
    "\n",
    "test_loss, test_acc = model.eval_(test_loader, criterion)\n",
    "print(f'Test Loss: {test_loss:.4f}, Test Accuracy: {test_acc:.4f}')\n",
    "\n",
    "torch.save(model.state_dict(), 'proposal_classifier.pth')\n",
    "print(\"Model saved as 'proposal_classifier.pth'.\")\n",
    "\n",
    "model.plot_training_history()\n",
    "model.plot_confusion_matrix(val_loader, label_encoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- - -\n",
    "## 4.2. ResNet18\n",
    "\n",
    "First we can import the ResNet18 pre-trained model and modify the last layer so that it only has two outputs, one for the 'pothole' class and one for the 'background' class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Models.ResNet18 import ResNet18\n",
    "\n",
    "num_epochs = 2\n",
    "batch_size = 32\n",
    "learning_rate = 1e-3\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, sampler=sampler)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "model = ResNet18(device, num_classes)\n",
    "\n",
    "class_weights_tensor = class_weights.to(device)\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights_tensor)\n",
    "optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=learning_rate)\n",
    "\n",
    "model.train_(train_loader, val_loader, num_epochs, criterion, optimizer)\n",
    "\n",
    "test_loss, test_acc = model.eval_(model, test_loader, criterion, device)\n",
    "print(f'Test Loss: {test_loss:.4f}, Test Accuracy: {test_acc:.4f}')\n",
    "\n",
    "torch.save(model.state_dict(), 'proposal_classifier_resnet.pth')\n",
    "print(\"Model saved as 'proposal_classifier_resnet.pth'.\")\n",
    "\n",
    "model.plot_training_history()\n",
    "model.plot_confusion_matrix(val_loader, label_encoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- - -\n",
    "## 4.3. VGG16\n",
    "\n",
    "We can do the same for the VGG16 model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Models.VGG16 import VGG16\n",
    "\n",
    "num_epochs = 2\n",
    "batch_size = 32\n",
    "learning_rate = 1e-3\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, sampler=sampler)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "model = VGG16(device, num_classes)\n",
    "\n",
    "class_weights_tensor = class_weights.to(device)\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights_tensor)\n",
    "optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=learning_rate)\n",
    "\n",
    "model, history = model.train_(train_loader, val_loader, num_epochs, criterion, optimizer)\n",
    "\n",
    "test_loss, test_acc = model.eval_(test_loader, criterion)\n",
    "print(f'Test Loss: {test_loss:.4f}, Test Accuracy: {test_acc:.4f}')\n",
    "\n",
    "torch.save(model.state_dict(), 'proposal_classifier_vgg16.pth')\n",
    "print(\"Model saved as 'proposal_classifier_vgg16.pth'.\")\n",
    "\n",
    "model.plot_training_history()\n",
    "model.plot_confusion_matrix(val_loader, label_encoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- - -\n",
    "- - -\n",
    "# 5. Evaluation\n",
    "> Evaluate the classification accuracy of the network on the validation set.\n",
    "> \n",
    "> ```admonition\n",
    "> Note that this is different from the evaluation of the object detection task.\n",
    "> ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- - -"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
